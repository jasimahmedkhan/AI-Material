{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "import joblib\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from numpy import ravel\r\n",
    "import pandas as pd\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier # The k-nearest neighbor classifier\r\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\r\n",
    "# Various pre-processing steps\r\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder\r\n",
    "from sklearn.model_selection import GridSearchCV  # For optimization\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "iris_df = load_iris()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "iris_df.data[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_df.data, iris_df.target, test_size=0.3, random_state=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Pipeline description\r\n",
    "# 1. Data Preprocessing by using Standard Scaler\r\n",
    "# 2. Reducing the dimesion of the PCA\r\n",
    "# 3. Apply Classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\r\n",
    "pipeline_lr = Pipeline(steps=[(\"scalar1\", StandardScaler()),\r\n",
    "                              (\"pca1\", PCA(n_components=2)),\r\n",
    "                              (\"lr_classifier\", LogisticRegression())])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "pipeline_dt = Pipeline(steps=[(\"scaler2\", StandardScaler()),\r\n",
    "                              (\"pca2\", PCA(n_components=2)),\r\n",
    "                              (\"dt_classifier\", DecisionTreeClassifier())])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "pipeline_rf = Pipeline(steps=[(\"scaler3\", StandardScaler()), \r\n",
    "                              (\"pca3\", PCA(n_components=2)), \r\n",
    "                              (\"rf_classifier\", RandomForestClassifier())])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "best_accuracy   = 0.0\r\n",
    "best_classifier = 0\r\n",
    "best_pipeline   = \" \""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\r\n",
    "pipe_dict = {0: \"Logistic Regression\", 1: \"Decision Tree\", 2: \"Random Forest\"}\r\n",
    "\r\n",
    "# Fit the Pipeline\r\n",
    "for pipe in pipelines:\r\n",
    "    pipe.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for i, model in enumerate(pipelines):\r\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i], model.score(X_test, y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression Test Accuracy: 0.9111111111111111\n",
      "Decision Tree Test Accuracy: 0.9333333333333333\n",
      "Random Forest Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "for i, model in enumerate(pipelines):\r\n",
    "    if model.score(X_test, y_test) > best_accuracy:\r\n",
    "        best_accuracy = model.score(X_test, y_test)\r\n",
    "        best_pipeline = model\r\n",
    "        best_classifier = i\r\n",
    "        \r\n",
    "print(\"Classifier with the best Accuracy: {}\".format(pipe_dict.get(best_classifier)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier with the best Accuracy: Decision Tree\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the Ecoli Dataset from the UCI Machine Learning Mastery\r\n",
    "#### https://machinelearningmastery.com/modeling-pipeline-optimization-with-scikit-learn/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "df = pd.read_csv(\r\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/ecoli/ecoli.data',\r\n",
    "    sep='\\s+',\r\n",
    "    header=None)\r\n",
    "print(df.head())\r\n",
    "## We’ll ignore the first column, which specifies the sequence name. \r\n",
    "# The last column is the class label. Let’s separate the features from the class label \r\n",
    "# and split the dataset into 2/3 training instances and 1/3 test examples.\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            0     1     2     3    4     5     6     7   8\n",
      "0   AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35  cp\n",
      "1  ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44  cp\n",
      "2  ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46  cp\n",
      "3  ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36  cp\n",
      "4   ADI_ECOLI  0.23  0.32  0.48  0.5  0.55  0.25  0.35  cp\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# The data matrix X\r\n",
    "X = df.iloc[:, 1:-1]\r\n",
    "# The labels\r\n",
    "y = (df.iloc[:, -1:])\r\n",
    "\r\n",
    "# Encode the labels into unique integers\r\n",
    "encoder = LabelEncoder()\r\n",
    "y = encoder.fit_transform(ravel(y))\r\n",
    "\r\n",
    "# Split the data into test and train\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(224, 7)\n",
      "(112, 7)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "##  For baseline Performance on the K-nearest neighbours \r\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\r\n",
    "print('Training set score: ' + str(knn.score(X_train, y_train)))\r\n",
    "print('Test set score: ' + str(knn.score(X_test, y_test))) \r\n",
    "## the trudgement is based on the score or accuracy results of the test dataset, \r\n",
    "# showing whether the classifie has generalized or not \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set score: 0.9017857142857143\n",
      "Test set score: 0.8482142857142857\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "pipeline_knn = Pipeline(steps=[(\"scaler\", StandardScaler()),\r\n",
    "                               (\"selector\", VarianceThreshold()),\r\n",
    "                               (\"classifier\", KNeighborsClassifier())])\r\n",
    "\r\n",
    "# Scaler: For pre-processing data, i.e., transform the data to zero mean and unit variance using the StandardScaler().\r\n",
    "# Feature selector: Use VarianceThreshold() for discarding features whose variance is less than a certain defined threshold.\r\n",
    "# Classifier: KNeighborsClassifier(), which implements the k-nearest neighbor classifier and selects the class of the majority k points, which are closest to the test example.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "pipeline_knn.fit(X_train, y_train)\r\n",
    "\r\n",
    "print('Training set score: ' + str(pipeline_knn.score(X_train, y_train)))\r\n",
    "print('Test set score: ' + str(pipeline_knn.score(X_test, y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set score: 0.8794642857142857\n",
      "Test set score: 0.8392857142857143\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimizing and Tuning the Pipeline\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "## We can search for the best scalers. Instead of just the StandardScaler(), we can try MinMaxScaler(), Normalizer() and MaxAbsScaler().\r\n",
    "## We can search for the best variance threshold to use in the selector, i.e., VarianceThreshold().\r\n",
    "## We can search for the best value of k for the KNeighborsClassifier().\r\n",
    "##  Note the following:\r\n",
    "#### The scaler has no double underscore, as we have specified a list of objects there.\r\n",
    "#### We would search for the best threshold for the selector, i.e., VarianceThreshold(). Hence we have specified a list of values[0, 0.0001, 0.001, 0.5] to choose from.\r\n",
    "#### Different values are specified for the n_neighbors, p and leaf_size parameters of the KNeighborsClassifier().\r\n",
    "\r\n",
    "parameters = {\"scaler\":[StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\r\n",
    "              \"selector__threshold\": [0, 0.001, 0.01],\r\n",
    "              \"classifier__n_neighbors\": [1, 3, 5, 7, 10], \r\n",
    "              \"classifier__p\": [1, 2], \r\n",
    "              \"classifier__leaf_size\": [1, 5, 10, 15]}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "grid = GridSearchCV(pipeline_knn, parameters, cv=2)\r\n",
    "grid.fit(X_train, y_train)\r\n",
    "\r\n",
    "print('Training set score: ' + str(grid.score(X_train, y_train)))\r\n",
    "print('Test set score: ' + str(grid.score(X_test, y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\SAIFUALLAH\\anaconda3\\envs\\beamng\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set score: 0.8928571428571429\n",
      "Test set score: 0.8571428571428571\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# # Access the best set of parameters\r\n",
    "# best_params = grid.best_params_\r\n",
    "# print(best_params)\r\n",
    "# # Stores the optimum model in best_pipe\r\n",
    "# best_pipe = grid.best_estimator_\r\n",
    "# print(best_pipe)\r\n",
    "\r\n",
    "# best_score = grid.best_score_\r\n",
    "# print(best_score)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'classifier__leaf_size': 1, 'classifier__n_neighbors': 7, 'classifier__p': 2, 'scaler': StandardScaler(), 'selector__threshold': 0}\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('selector', VarianceThreshold(threshold=0)),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(leaf_size=1, n_neighbors=7))])\n",
      "0.84375\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # result_df = pd.DataFrame.from_dict(grid.cv_results_, orient='columns')\r\n",
    "# result_df = pd.DataFrame.from_dict(grid.cv_results_)\r\n",
    "# result_df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('beamng': conda)"
  },
  "interpreter": {
   "hash": "5f006ca1e7b07a4469d28a15f4b49f6cd4001dfb127788cbd6b3b8ec08bd5d42"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}